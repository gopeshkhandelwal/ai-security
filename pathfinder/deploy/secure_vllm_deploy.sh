#!/bin/bash
#
# Pathfinder Secure Model Deployment for Intel vLLM
#
# This script implements secure-by-default model enablement:
#   1. Clone/update Pathfinder security tools
#   2. Download model to quarantine
#   3. Run security scans (ModelScan, PickleScan, AST patterns)
#   4. Only proceed to serving if scans pass
#   5. Serve with security-hardened settings
#
# Usage:
#   ./secure_vllm_deploy.sh <model-id> [--skip-scan] [--force]
#
# Examples:
#   ./secure_vllm_deploy.sh meta-llama/Llama-3.1-8B
#   ./secure_vllm_deploy.sh mistralai/Mistral-7B-v0.1
#
# Author: AI Model Pathfinder Security Team
# License: MIT

set -euo pipefail

# =============================================================================
# CONFIGURATION
# =============================================================================

# Model to deploy (can be overridden by argument)
MODEL_ID="${1:-meta-llama/Llama-3.1-8B}"
MODEL_NAME=$(echo "$MODEL_ID" | sed 's/.*\///')

# Paths
MODELS_DIR="/home/compat/models/vLLM"
QUARANTINE_DIR="${MODELS_DIR}/quarantine"
VERIFIED_DIR="${MODELS_DIR}/verified"
PATHFINDER_DIR="${MODELS_DIR}/pathfinder"
SCAN_RESULTS_DIR="${MODELS_DIR}/scan-results"
LOGS_DIR="/llm/logs"

# Container settings
CONTAINER_NAME="lsv-container"
CONTAINER_IMAGE="intel/llm-scaler-vllm:1.2"

# vLLM settings
VLLM_PORT=8001
VLLM_HOST="0.0.0.0"

# Security settings
TRUST_REMOTE_CODE="false"  # Default: DISABLED for security
SKIP_SCAN="${SKIP_SCAN:-false}"
FORCE_DEPLOY="${FORCE_DEPLOY:-false}"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[âœ“]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[âš ]${NC} $1"
}

log_error() {
    echo -e "${RED}[âœ—]${NC} $1"
}

log_header() {
    echo ""
    echo "============================================================"
    echo "  $1"
    echo "============================================================"
    echo ""
}

check_command() {
    if ! command -v "$1" &> /dev/null; then
        log_error "$1 is required but not installed."
        exit 1
    fi
}

# =============================================================================
# STEP 0: PREREQUISITES
# =============================================================================

step_0_prerequisites() {
    log_header "STEP 0: Prerequisites Check"
    
    check_command docker
    check_command git
    
    # Check if HF_TOKEN is set
    if [ -z "${HF_TOKEN:-}" ]; then
        log_warning "HF_TOKEN not set. Some models may not be accessible."
        log_info "Set with: export HF_TOKEN='hf_...'"
    else
        log_success "HF_TOKEN is set"
    fi
    
    # Create directories
    sudo mkdir -p "$MODELS_DIR"
    sudo mkdir -p "$QUARANTINE_DIR"
    sudo mkdir -p "$VERIFIED_DIR"
    sudo mkdir -p "$SCAN_RESULTS_DIR"
    sudo mkdir -p "$LOGS_DIR"
    
    # Set permissions
    sudo chmod -R 777 "$MODELS_DIR"
    
    log_success "Prerequisites check passed"
}

# =============================================================================
# STEP 1: CLONE/UPDATE PATHFINDER SECURITY TOOLS
# =============================================================================

step_1_setup_pathfinder() {
    log_header "STEP 1: Setup Pathfinder Security Tools"
    
    if [ -d "$PATHFINDER_DIR" ]; then
        log_info "Updating existing Pathfinder installation..."
        cd "$PATHFINDER_DIR"
        git fetch origin
        git checkout main
        git pull origin main
        log_success "Pathfinder updated"
    else
        log_info "Cloning Pathfinder repository..."
        cd "$MODELS_DIR"
        
        # Clone the ai-security repo (adjust URL as needed)
        git clone https://github.com/your-org/ai-security.git pathfinder || {
            log_warning "Could not clone from remote. Creating local structure..."
            mkdir -p "$PATHFINDER_DIR/security"
            
            # Create minimal scanner inline if repo not available
            cat > "$PATHFINDER_DIR/security/pathfinder_scanner.py" << 'SCANNER_EOF'
#!/usr/bin/env python3
"""Pathfinder Security Scanner - Minimal Version"""
import re
import json
import hashlib
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Optional
from enum import Enum
from datetime import datetime

class Severity(Enum):
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"

@dataclass
class Finding:
    scanner: str
    severity: Severity
    category: str
    message: str
    file: Optional[str] = None

@dataclass
class ScanResult:
    model_path: str
    timestamp: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    passed: bool = True
    findings: List[Finding] = field(default_factory=list)
    
    def to_json(self):
        return json.dumps({
            "model_path": self.model_path,
            "timestamp": self.timestamp,
            "passed": self.passed,
            "findings": [{"severity": f.severity.value, "category": f.category, 
                         "message": f.message, "file": f.file} for f in self.findings]
        }, indent=2)

DANGEROUS_PATTERNS = [
    (r'socket\.socket', 'NETWORK_SOCKET', 'Network socket creation'),
    (r'os\.fork\s*\(\)', 'PROCESS_FORK', 'Process forking'),
    (r'subprocess', 'SUBPROCESS', 'Subprocess execution'),
    (r'pty\.spawn', 'PTY_SPAWN', 'PTY shell spawning'),
    (r'os\.dup2', 'FD_REDIRECT', 'File descriptor redirection'),
    (r'exec\s*\(|eval\s*\(', 'DYNAMIC_EXEC', 'Dynamic code execution'),
    (r'os\.system', 'OS_SYSTEM', 'System command execution'),
    (r'pickle\.load', 'PICKLE_LOAD', 'Pickle deserialization'),
    (r'torch\.load', 'TORCH_LOAD', 'PyTorch load (uses pickle)'),
]

BLOCKED_FORMATS = ['.pkl', '.pickle', '.pt', '.pth', '.bin']

class PathfinderScanner:
    def __init__(self, strict_mode=True, allow_pickle=False):
        self.strict_mode = strict_mode
        self.allow_pickle = allow_pickle
    
    def scan_model(self, model_path: str) -> ScanResult:
        model_path = Path(model_path)
        result = ScanResult(model_path=str(model_path))
        
        # Check file formats
        for f in model_path.rglob("*"):
            if f.is_file() and f.suffix in BLOCKED_FORMATS and not self.allow_pickle:
                result.findings.append(Finding(
                    scanner="FormatChecker",
                    severity=Severity.CRITICAL,
                    category="BLOCKED_FORMAT",
                    message=f"Blocked format: {f.suffix}",
                    file=str(f.name)
                ))
                result.passed = False
        
        # Scan Python files
        for py_file in model_path.rglob("*.py"):
            try:
                content = py_file.read_text()
                for pattern, category, desc in DANGEROUS_PATTERNS:
                    if re.search(pattern, content):
                        sev = Severity.CRITICAL if category in ['NETWORK_SOCKET', 'SUBPROCESS', 'PTY_SPAWN'] else Severity.HIGH
                        result.findings.append(Finding(
                            scanner="CodePatternScanner",
                            severity=sev,
                            category=category,
                            message=desc,
                            file=str(py_file.name)
                        ))
                        result.passed = False
            except: pass
        
        # Check trust_remote_code requirement
        config_path = model_path / "config.json"
        if config_path.exists():
            try:
                config = json.loads(config_path.read_text())
                if "auto_map" in config:
                    result.findings.append(Finding(
                        scanner="TrustRemoteCodeChecker",
                        severity=Severity.HIGH,
                        category="TRUST_REMOTE_CODE_REQUIRED",
                        message="Model requires trust_remote_code=True",
                        file="config.json"
                    ))
                    result.passed = False
            except: pass
        
        return result

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        scanner = PathfinderScanner()
        result = scanner.scan_model(sys.argv[1])
        print(result.to_json())
        sys.exit(0 if result.passed else 1)
SCANNER_EOF
        }
        
        log_success "Pathfinder setup complete"
    fi
    
    # Checkout pathfinder branch if it exists
    cd "$PATHFINDER_DIR" 2>/dev/null && {
        git checkout pathfinder 2>/dev/null || git checkout main 2>/dev/null || true
    } || true
}

# =============================================================================
# STEP 2: PULL CONTAINER IMAGE
# =============================================================================

step_2_pull_container() {
    log_header "STEP 2: Pull Intel vLLM Container"
    
    log_info "Pulling container image: $CONTAINER_IMAGE"
    docker pull "$CONTAINER_IMAGE"
    
    log_success "Container image pulled"
}

# =============================================================================
# STEP 3: START CONTAINER (if not running)
# =============================================================================

step_3_start_container() {
    log_header "STEP 3: Start Container"
    
    # Check if container exists and is running
    if docker ps -q -f name="$CONTAINER_NAME" | grep -q .; then
        log_info "Container '$CONTAINER_NAME' is already running"
    elif docker ps -aq -f name="$CONTAINER_NAME" | grep -q .; then
        log_info "Starting existing container '$CONTAINER_NAME'..."
        docker start "$CONTAINER_NAME"
    else
        log_info "Creating new container '$CONTAINER_NAME'..."
        
        sudo docker run -td \
            --privileged \
            --net=host \
            --device=/dev/dri \
            --name="$CONTAINER_NAME" \
            -v "$MODELS_DIR:/llm/models/" \
            -v "$PATHFINDER_DIR:/llm/pathfinder/" \
            -e no_proxy=localhost,127.0.0.1 \
            -e http_proxy="${http_proxy:-}" \
            -e https_proxy="${https_proxy:-}" \
            -e PYTHONPATH=/llm/pathfinder \
            --shm-size="32g" \
            --entrypoint /bin/bash \
            "$CONTAINER_IMAGE"
    fi
    
    # Wait for container to be ready
    sleep 2
    
    # Verify container is running
    if docker ps -q -f name="$CONTAINER_NAME" | grep -q .; then
        log_success "Container is running"
        
        # Show GPU info
        log_info "Checking GPU availability..."
        docker exec "$CONTAINER_NAME" xpu-smi discovery 2>/dev/null || log_warning "xpu-smi not available"
    else
        log_error "Failed to start container"
        exit 1
    fi
}

# =============================================================================
# STEP 4: DOWNLOAD MODEL TO QUARANTINE
# =============================================================================

step_4_download_model() {
    log_header "STEP 4: Download Model to Quarantine"
    
    QUARANTINE_MODEL_DIR="$QUARANTINE_DIR/$MODEL_NAME"
    
    # Check if already downloaded
    if [ -d "$QUARANTINE_MODEL_DIR" ] && [ "$(ls -A "$QUARANTINE_MODEL_DIR" 2>/dev/null)" ]; then
        log_info "Model already in quarantine: $QUARANTINE_MODEL_DIR"
        if [ "$FORCE_DEPLOY" != "true" ]; then
            log_info "Use --force to re-download"
            return 0
        fi
        log_warning "Force flag set, re-downloading..."
        rm -rf "$QUARANTINE_MODEL_DIR"
    fi
    
    log_info "Downloading model: $MODEL_ID"
    log_info "Destination: $QUARANTINE_MODEL_DIR (QUARANTINE)"
    
    # Download using huggingface-cli inside container
    docker exec -e HF_TOKEN="${HF_TOKEN:-}" -e HF_HOME="/llm/models/quarantine" "$CONTAINER_NAME" \
        python3 -c "
from huggingface_hub import snapshot_download
import os

token = os.environ.get('HF_TOKEN')
model_id = '$MODEL_ID'
local_dir = '/llm/models/quarantine/$MODEL_NAME'

print(f'Downloading {model_id} to {local_dir}...')
snapshot_download(
    repo_id=model_id,
    local_dir=local_dir,
    token=token if token else None,
    local_dir_use_symlinks=False
)
print('Download complete!')
"
    
    if [ -d "$QUARANTINE_MODEL_DIR" ]; then
        log_success "Model downloaded to quarantine"
        log_info "Files:"
        ls -la "$QUARANTINE_MODEL_DIR" | head -10
    else
        log_error "Model download failed"
        exit 1
    fi
}

# =============================================================================
# STEP 5: SECURITY SCAN
# =============================================================================

step_5_security_scan() {
    log_header "STEP 5: Security Scan"
    
    if [ "$SKIP_SCAN" == "true" ]; then
        log_warning "SECURITY SCAN SKIPPED (--skip-scan flag)"
        log_warning "This is NOT recommended for production!"
        return 0
    fi
    
    QUARANTINE_MODEL_DIR="$QUARANTINE_DIR/$MODEL_NAME"
    SCAN_RESULT_FILE="$SCAN_RESULTS_DIR/${MODEL_NAME}_scan_$(date +%Y%m%d_%H%M%S).json"
    
    log_info "Scanning model for security issues..."
    log_info "Model path: $QUARANTINE_MODEL_DIR"
    
    # Install scanning tools in container
    log_info "Installing security scanning tools..."
    docker exec "$CONTAINER_NAME" pip install -q modelscan picklescan 2>/dev/null || true
    
    # Run Pathfinder scanner
    log_info "Running Pathfinder security scanner..."
    
    SCAN_OUTPUT=$(docker exec -e PYTHONPATH=/llm/pathfinder "$CONTAINER_NAME" \
        python3 /llm/pathfinder/security/pathfinder_scanner.py "/llm/models/quarantine/$MODEL_NAME" 2>&1) || true
    
    echo "$SCAN_OUTPUT" > "$SCAN_RESULT_FILE"
    
    # Parse result
    if echo "$SCAN_OUTPUT" | grep -q '"passed": true'; then
        log_success "Security scan PASSED"
        echo "$SCAN_OUTPUT" | python3 -c "import sys,json; d=json.load(sys.stdin); print(f'  Findings: {len(d.get(\"findings\",[]))}'); [print(f'    - {f[\"category\"]}: {f[\"message\"]}') for f in d.get('findings',[])]" 2>/dev/null || true
        return 0
    else
        log_error "Security scan FAILED"
        echo ""
        echo "$SCAN_OUTPUT" | python3 -c "
import sys, json
try:
    d = json.load(sys.stdin)
    print('Findings:')
    for f in d.get('findings', []):
        sev = f.get('severity', 'UNKNOWN')
        icon = 'ğŸš¨' if sev == 'CRITICAL' else 'âš ï¸' if sev == 'HIGH' else 'â„¹ï¸'
        print(f'  {icon} [{sev}] {f[\"category\"]}')
        print(f'      {f[\"message\"]}')
        if f.get('file'):
            print(f'      File: {f[\"file\"]}')
except:
    print(sys.stdin.read())
" 2>/dev/null || echo "$SCAN_OUTPUT"
        
        echo ""
        log_error "Model blocked due to security findings!"
        log_info "Scan results saved to: $SCAN_RESULT_FILE"
        log_info ""
        log_info "To proceed anyway (NOT RECOMMENDED):"
        log_info "  export SKIP_SCAN=true"
        log_info "  $0 $MODEL_ID"
        
        return 1
    fi
}

# =============================================================================
# STEP 6: PROMOTE TO VERIFIED
# =============================================================================

step_6_promote_model() {
    log_header "STEP 6: Promote Model to Verified"
    
    QUARANTINE_MODEL_DIR="$QUARANTINE_DIR/$MODEL_NAME"
    VERIFIED_MODEL_DIR="$VERIFIED_DIR/$MODEL_NAME"
    
    if [ -d "$VERIFIED_MODEL_DIR" ]; then
        log_info "Removing old verified model..."
        rm -rf "$VERIFIED_MODEL_DIR"
    fi
    
    log_info "Moving model from quarantine to verified..."
    mv "$QUARANTINE_MODEL_DIR" "$VERIFIED_MODEL_DIR"
    
    # Generate MLBOM (Machine Learning Bill of Materials)
    log_info "Generating MLBOM..."
    cat > "$VERIFIED_MODEL_DIR/mlbom.json" << MLBOM_EOF
{
    "mlbom_version": "1.0",
    "generated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "model": {
        "id": "$MODEL_ID",
        "name": "$MODEL_NAME",
        "local_path": "$VERIFIED_MODEL_DIR"
    },
    "security": {
        "scan_passed": true,
        "scan_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
        "trust_remote_code": $TRUST_REMOTE_CODE,
        "format": "safetensors"
    },
    "provenance": {
        "source": "huggingface.co",
        "downloaded_by": "$(whoami)",
        "host": "$(hostname)"
    }
}
MLBOM_EOF
    
    log_success "Model promoted to verified: $VERIFIED_MODEL_DIR"
    log_info "MLBOM generated: $VERIFIED_MODEL_DIR/mlbom.json"
}

# =============================================================================
# STEP 7: SERVE MODEL
# =============================================================================

step_7_serve_model() {
    log_header "STEP 7: Serve Model with vLLM"
    
    VERIFIED_MODEL_DIR="/llm/models/verified/$MODEL_NAME"
    
    log_info "Starting vLLM server..."
    log_info "Model: $VERIFIED_MODEL_DIR"
    log_info "Port: $VLLM_PORT"
    log_info "trust_remote_code: $TRUST_REMOTE_CODE"
    
    # Build vLLM command
    VLLM_CMD="HF_TOKEN='${HF_TOKEN:-}' \
HF_HOME='/llm/models' \
VLLM_ALLOW_LONG_MAX_MODEL_LEN=1 \
VLLM_WORKER_MULTIPROC_METHOD=spawn \
vllm serve '$VERIFIED_MODEL_DIR' \
    --served-model-name '$MODEL_NAME' \
    --dtype=float16 \
    --enforce-eager \
    --port $VLLM_PORT \
    --host $VLLM_HOST \
    --disable-sliding-window \
    --gpu-memory-util=0.9 \
    --no-enable-prefix-caching \
    --max-num-batched-tokens=8192 \
    --disable-log-requests \
    --max-model-len=8192 \
    --block-size 64 \
    --quantization fp8 \
    -tp=1"
    
    # Only add trust-remote-code if explicitly enabled
    if [ "$TRUST_REMOTE_CODE" == "true" ]; then
        log_warning "trust_remote_code is ENABLED - ensure model was reviewed!"
        VLLM_CMD="$VLLM_CMD --trust-remote-code"
    fi
    
    VLLM_CMD="$VLLM_CMD 2>&1 | tee /llm/vllm.log > /proc/1/fd/1 &"
    
    # Start vLLM
    docker exec -d "$CONTAINER_NAME" bash -c "$VLLM_CMD"
    
    log_success "vLLM server starting..."
    log_info "View logs: docker exec $CONTAINER_NAME tail -f /llm/vllm.log"
    log_info "Test endpoint: curl http://localhost:$VLLM_PORT/v1/models"
    
    # Wait and check if server started
    log_info "Waiting for server to start..."
    sleep 10
    
    if curl -s "http://localhost:$VLLM_PORT/v1/models" | grep -q "$MODEL_NAME"; then
        log_success "vLLM server is running!"
        echo ""
        echo "API Endpoint: http://localhost:$VLLM_PORT/v1"
        echo "Model Name: $MODEL_NAME"
    else
        log_warning "Server may still be loading. Check logs:"
        log_info "docker exec $CONTAINER_NAME tail -f /llm/vllm.log"
    fi
}

# =============================================================================
# STEP 8: RUN BENCHMARK (Optional)
# =============================================================================

step_8_benchmark() {
    log_header "STEP 8: Run Benchmark (Optional)"
    
    VERIFIED_MODEL_DIR="/llm/models/verified/$MODEL_NAME"
    
    log_info "Running vLLM benchmark..."
    
    docker exec "$CONTAINER_NAME" bash -c "
vllm bench serve \
    --model '$VERIFIED_MODEL_DIR' \
    --dataset-name random \
    --served-model-name '$MODEL_NAME' \
    --random-input-len=1024 \
    --random-output-len=512 \
    --ignore-eos \
    --num-prompt 10 \
    --request-rate inf \
    --backend vllm \
    --port=$VLLM_PORT
"
    
    log_success "Benchmark complete"
}

# =============================================================================
# MAIN EXECUTION
# =============================================================================

main() {
    echo ""
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                                                                           â•‘"
    echo "â•‘              AI Model Pathfinder - Secure Model Deployment                â•‘"
    echo "â•‘                                                                           â•‘"
    echo "â•‘  Security-first model enablement for Intel vLLM                           â•‘"
    echo "â•‘                                                                           â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    echo "Model: $MODEL_ID"
    echo "Container: $CONTAINER_NAME"
    echo ""
    
    # Parse arguments
    for arg in "$@"; do
        case $arg in
            --skip-scan)
                SKIP_SCAN="true"
                log_warning "Security scan will be SKIPPED"
                ;;
            --force)
                FORCE_DEPLOY="true"
                log_info "Force mode enabled"
                ;;
            --trust-remote-code)
                TRUST_REMOTE_CODE="true"
                log_warning "trust_remote_code will be ENABLED"
                ;;
            --benchmark)
                RUN_BENCHMARK="true"
                ;;
        esac
    done
    
    # Run steps
    step_0_prerequisites
    step_1_setup_pathfinder
    step_2_pull_container
    step_3_start_container
    step_4_download_model
    
    # Security gate
    if step_5_security_scan; then
        step_6_promote_model
        step_7_serve_model
        
        if [ "${RUN_BENCHMARK:-false}" == "true" ]; then
            step_8_benchmark
        fi
        
        log_header "Deployment Complete"
        log_success "Model $MODEL_NAME is now serving securely!"
        echo ""
        echo "Summary:"
        echo "  âœ“ Model downloaded and scanned"
        echo "  âœ“ Security checks passed"
        echo "  âœ“ Model promoted to verified store"
        echo "  âœ“ vLLM server running on port $VLLM_PORT"
        echo ""
        echo "Next steps:"
        echo "  - Test: curl http://localhost:$VLLM_PORT/v1/models"
        echo "  - Logs: docker exec $CONTAINER_NAME tail -f /llm/vllm.log"
        echo "  - Benchmark: $0 $MODEL_ID --benchmark"
    else
        log_header "Deployment Blocked"
        log_error "Model failed security scan and was NOT deployed."
        echo ""
        echo "The model remains in quarantine: $QUARANTINE_DIR/$MODEL_NAME"
        echo ""
        echo "Options:"
        echo "  1. Review findings and choose a different model"
        echo "  2. Request security exception (requires approval)"
        echo "  3. Skip scan (NOT RECOMMENDED): $0 $MODEL_ID --skip-scan"
        exit 1
    fi
}

# Run main with all arguments
main "$@"
